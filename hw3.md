## Домашнее задание 3

**Тема: векторные модели и TF-IDF**

**Дедлайн: 8 ноября 23:59**

**Важное: работы принимаются строго в ipynb (не скрипт, не скрипт в ячейке ipynb)**

### Данные

1. Книги для обучения своей модели (см. п. 1)
2. Сайт rusvectores

Большая часть кода уже есть в конспектах, обращайтесь к ним.

### Задание

**1. Общая оценка до 2 баллов**

**Word2Vec**
1. Возьмите несколько книг (например, с lib.ru) (от 10 книг), желательно, из одной серии или схожей тематики. 
2. Подготовьте тексты для обучения модели
    - лемматизируйте тексты
    - приведите к нижнему регистру
    - уберите знаки препинания
    - исключите стоп-слова (предлоги, местоимения и прочее)
    - запишите все тексты в один файл, каждое предложение на отдельной строке (для деления на предложения можно использовать sentence tokenizer из NLTK)

**2. Общая оценка до 6 баллов**

1. Обучите модель как показано в конспекте по word2vec с параметрами
  - размер вектора 300
  - минимальное количество вхождений 5
  - окно 5
  - количество итераций 50
2. Сколько слов оказалось в словаре? Это много или мало? 
3. Найдите ближайшие 10 слов для:
  - абстрактного понятия
  - имени героя
  - прилагательных хороший и плохой (или других антонимов)
4. Кратко результаты предыдущего пункта: 
  - насколько ожидаем такой результат? есть ли неожиданные соседи?
  - есть ли синонимы / антонимы в ближайших к слову?
  - говорит ли это что-то о самом корпусе? (есть какие особенности относительно языка в целом)
5. Найдите лишнее слово в ряду. Соответствует ли результат ожиданиям или модель ошиблась?

**3 Общая оценка до 8 баллов**

**3.1 W2V**
1. Скачайте и загрузите одну из Word2Vec моделей с сайта rusvectores
2. Придумайте какую-то свою семантическую пропорцию (Россия - Москва + Испания = Мадрид, король - мужчина + королева = женщина)
3. Попробуйте сделать визуализацию с помощью PCA (**один** из вариантов на выбор, можно предложить свой)
  - попробуйте на каких-то названиях предметов или животных: насколько это похоже на правду? 
  - попробуйте для абстрактных понятий (например, любовь-дружба-преданность-...)
  - попробуйте на многозначных словах: насколько результат соответствует Вашим ожиданиям?
4. Возьмите какое-нибудь предложение (не менее 10 слов) и замените все слова (которые не являются служебными) на ближайшие по векторам, можно просто в лемматизированном виде, потом просто вручную написать его, чтобы все согласовывалось.

**3.2 TF-IDF**
1. Возьмите статьи (20-100) из Википедии на разные темы (например, про города, страны, математику, историю, языки), подготовьте для построения TF-IDF (лемматизируйте)
2. Постройте TF-IDF для статей. Параметры от 1 до 3 слов, встретились минимум 3 раза.
3. Выделите для них ключевые слова, покажите их и оцените, насколько это соответствует их содержанию и вашим ожиданиям.
3. С помощью PCA визуализируйте TF-IDF вектора текстов (как в семантике, просто вместо семантических векторов tf-idf). Правда ли, что похожие тексты находятся рядом?

**4. Общая оценка до 10 баллов (продвинутый уровень)**

**Семантика. Проект rusvectores**

Зайдите на сайт проекта.

(Для пунктов копируйте списки слов, которые на сайте получаются из моделей, в тетрадку в маркдаун)

1. Раздел похожие слова
    - возьмите 3 слова (абстрактное понятие распространенное, научный термин, название предмета быта)
    - посмотрите на ближайшие слова в моделях (все галочки)
    - прокомментируйте, как отличаются списки соседей и говорит ли это что-то о содержании текстов в корпусе?
3. Раздел визуализация
    - возьмите слова, обозначающие разные эмоции (10 слов) и визуализируйте, как они располагаются относительно друг друга
    - сохраните картинку на гитхаб
5. Раздел Калькулятор
    - составьте интересную пропорцию, сравните, что предлагают разные модели
7. Раздел 2D-текст
    - возьмите 1 пословицу и 1 обычное предложение, прокомментируйте, насколько адекватно предлагаются замены, 

**TF-IDF**
2. Попробуйте разобраться с параметром token_pattern, как задать параметр так, чтобы числа не попадали в словарь?
3. Прочитайте про метрику cosine_similarity в sklearn. С помощью нее постройте матрицу схожести текстов на основе их векторов.
    - возьмите один из текстов и выведите тексты, которые наиболее на него похожи
5. Прочитайте про seaborn clustermap и попробуйте визуализировать матрицу близости.
    - подпишите названия текстов
    - посмотрите на то, как кластеризуются тексты, прокомментируйте, похоже ли это на адекватную оценку?

**Чек-лист**

1. Тетрадки с кодом
2. НЕ надо прикреплять вашу модель

Если у вас есть вопросы, задавайте в чате или пишите преподавателям


**Ссылки на GiHub Classroom:**

[Группа 201](https://classroom.github.com/a/zJ_aC1ZY)

[Группа 202](https://classroom.github.com/a/QhQDne56) 

[Группа 203](https://classroom.github.com/a/9rbI4Ncn) 

[Группа 204](https://classroom.github.com/a/drlwipuH) 
